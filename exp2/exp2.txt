episodes = 10000
# whether only AIs are in the game or one AI and random bots
only_ais = False
load = False # whether to load the models' weights
verbose = False # whether to print game progress
feature_type = 2 # 1, 2 or (unsupported) 3
# starting value for how often a random action is taken by AIs
# linearly anneals min_epsilon in the first epsilon_count actions
min_epsilon = 0.1
epsilon = 1 # if not load else min_epsilon
epsilon_count = 6000
# learning rates
alpha_actor = 0.001
alpha_critic = 0.001
# update factors
tau_actor = 0.001
tau_critic = 0.001
# number of hidden neurons in each layer
n1_actor = 50
n1_critic = 50
n2_actor = 50
n2_critic = 50
gamma = 0.99 # discount factor
max_experience_count = 500 # amount of experiences to store
batch_size = 32 # amount of experiences to replay
win_reward = 70
loss_reward = -70
wait_reward = -1
illegal_action_reward = -100
# whether the features always contain 52 cards even though less are
# necessary (so that shape is the same for any amount of cards)
buffer_features = False
# how often random bots wait
# calculated from a normal distribution with the given values
psi_mu = 0.95
psi_sigma = 0.1
# how often bots check
# calculated from a normal distribution with the given values
chi_mu = 0.08
chi_sigma = 0.1
action_shape = 5

# 'Kraudia' is added automatically if only_ais is false
names = ['Alice', 'Bob']
deck_size = 12
hand_size = 3
trump_suit = 2 # hearts (better not change this for consistency)


win rate was not very stable
time = 25195.38 seconds (7 hours)

after this experiment, epsilon was changed to anneal after each episode instead of after each action (which included other players!)